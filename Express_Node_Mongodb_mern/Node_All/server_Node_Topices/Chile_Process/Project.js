âš™ï¸ 3ï¸âƒ£ Basic Cluster Example
// clusterServer.js
const cluster = require("cluster");
const os = require("os");
const http = require("http");

if (cluster.isMaster) {
  const numCPUs = os.cpus().length;
  console.log(`ğŸ§  Master process running (PID: ${process.pid})`);
  console.log(`ğŸ”§ Spawning ${numCPUs} workers...\n`);

  // Fork workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  // Listen for worker exit
  cluster.on("exit", (worker) => {
    console.log(`âŒ Worker ${worker.process.pid} died. Restarting...`);
    cluster.fork();
  });
} else {
  // Workers create HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`âœ… Response from worker ${process.pid}\n`);
  }).listen(3000);

  console.log(`ğŸš€ Worker ${process.pid} started`);
}

Run it:
node clusterServer.js


ğŸ§© Youâ€™ll see multiple workers created â€” one per CPU core.

Now open multiple browser tabs or run:

curl localhost:3000


Each response will come from a different worker process (check PID).

âš™ï¸ 4ï¸âƒ£ Why Itâ€™s Powerful (Design Benefits)

âœ… Full CPU utilization â€“ uses all cores.
âœ… Scalable â€“ handle more requests concurrently.
âœ… Fault tolerance â€“ if one worker dies, master restarts it.
âœ… Non-blocking main process â€“ each worker runs separately.
âœ… Horizontal scaling ready â€“ easy to combine with Docker/K8s.



ğŸ§  5ï¸âƒ£ Best Cluster Design Pattern

Hereâ€™s a clean production-ready pattern (used in real-world systems):

/project
 â”œâ”€â”€ server.js       // Main API logic (Express/HTTP)
 â”œâ”€â”€ cluster.js      // Cluster manager
 â”œâ”€â”€ worker.js       // Worker handler
 â””â”€â”€ utils/
      â””â”€â”€ logger.js



      ğŸ§© cluster.js
const cluster = require("cluster");
const os = require("os");

if (cluster.isMaster) {
  const numCPUs = os.cpus().length;
  console.log(`ğŸ‘‘ Master PID: ${process.pid}`);
  console.log(`ğŸ§© Spawning ${numCPUs} workers...\n`);

  for (let i = 0; i < numCPUs; i++) cluster.fork();

  cluster.on("exit", (worker) => {
    console.error(`ğŸ’€ Worker ${worker.process.pid} crashed, restarting...`);
    cluster.fork();
  });
} else {
  require("./server"); // Each worker runs your main app
}

ğŸ§© server.js
const express = require("express");
const app = express();

app.get("/", (req, res) => {
  res.send(`Hello from worker ${process.pid}`);
});

app.listen(3000, () => {
  console.log(`Worker ${process.pid} running on port 3000`);
});


âœ… Design Advantages

Clean separation: cluster logic vs. business logic

Auto-restart on crash

Reusable structure for APIs

Works in Docker and production scaling setups

ğŸ¯ 6ï¸âƒ£ Real-World Example

Used by major apps like:

PM2, NGINX, Express clusters

E-commerce servers handling thousands of requests/minute

Event processing and background job workers



ğŸ§© 8ï¸âƒ£ Cluster vs Child Process vs Worker Threads


| Feature       | Cluster                | Child Process     | Worker Threads         |
| ------------- | ---------------------- | ----------------- | ---------------------- |
| Based on      | `child_process.fork()` | `child_process`   | `worker_threads`       |
| Memory        | Separate               | Separate          | Shared                 |
| Communication | Message passing        | Message passing   | Shared memory          |
| Use Case      | Web/API scaling        | External commands | CPU-intensive JS tasks |
| Isolation     | High                   | High              | Medium                 |


ğŸ§  9ï¸âƒ£ Common Real System Design Question

â€œHow would you scale a Node.js application to handle 10k+ concurrent requests?â€

âœ… Answer Outline:

Use cluster module to utilize all CPU cores.

Each worker handles part of the load.

Use a load balancer (NGINX or PM2) to distribute requests across containers.

Use Redis caching to offload repeated queries.

Optionally, add Kafka or RabbitMQ for background jobs.




